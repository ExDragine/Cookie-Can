{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchtoolbox.transform import Cutout\n",
    "from torchtoolbox.tools import mixup_data, mixup_criterion\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_status = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if code_status == 1:\n",
    "    lr = 1e-4\n",
    "    batchSize = 4\n",
    "    epochs = 1\n",
    "else:\n",
    "    lr = 1e-4\n",
    "    batchSize = 128\n",
    "    workers = 16\n",
    "    epochs = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if code_status == 1:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandAugment(),\n",
    "        transforms.RandomAutocontrast(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        Cutout(0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandAugment(),\n",
    "        transforms.RandomAutocontrast(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        Cutout(0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = {\"Basalt\": 0, \"Highland\": 1}\n",
    "#Labels = {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6}\n",
    "num_classes = len(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeedlingData(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, transforms=None, train=True, test=False):\n",
    "        self.test = test\n",
    "        self.transforms = transforms\n",
    "        if self.test:\n",
    "            imgs = [os.path.join(root, img) for img in os.listdir(root)]\n",
    "            self.imgs = imgs\n",
    "        else:\n",
    "            img_labels = [os.path.join(root, img) for img in os.listdir(root)]\n",
    "            imgs = []\n",
    "            for imglabel in img_labels:\n",
    "                for imgname in os.listdir(imglabel):\n",
    "                    imgpath = os.path.join(imglabel, imgname)\n",
    "                    imgs.append(imgpath)\n",
    "            trainval_file, val_file = train_test_split(imgs,\n",
    "                                                       test_size=0.3,\n",
    "                                                       random_state=42)\n",
    "            if train:\n",
    "                self.imgs = trainval_file\n",
    "            else:\n",
    "                self.imgs = val_file\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "        img_path = img_path.replace(\"\\\\\", \"/\")\n",
    "        if self.test:\n",
    "            label = -1\n",
    "        else:\n",
    "            labelname = img_path.split(\"/\")[-2]\n",
    "            label = Labels[labelname]\n",
    "        data = Image.open(img_path).convert(\"RGB\")\n",
    "        data = self.transforms(data)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SeedlingData(\"./datasets/train\",\n",
    "                             transforms=transform,\n",
    "                             train=True)\n",
    "dataset_test = SeedlingData(\"./datasets/train\",\n",
    "                            transforms=transform,\n",
    "                            train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=batchSize,\n",
    "    # num_workers=workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_test,\n",
    "    batch_size=batchSize,\n",
    "    # num_workers=workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALEX = models.alexnet(pretrained=True, progress=True, num_classes=num_classes)\n",
    "VGG = models.vgg19(pretrained=True, progress=True, num_classes=num_classes)\n",
    "RESNET = models.resnet50(pretrained=True,\n",
    "                         progress=True,\n",
    "                         num_classes=num_classes)\n",
    "GOOGLE = models.googlenet(pretrained=True,\n",
    "                          progress=True,\n",
    "                          num_classes=num_classes,\n",
    "                          init_weights=True)\n",
    "DENSE = models.densenet169(pretrained=True,progress=True,num_classes=num_classes)\n",
    "MOBILE = models.mobilenet_v3_large(pretrained=True,\n",
    "                                   progress=True,\n",
    "                                   num_classes=num_classes)\n",
    "CONVNEXT = models.convnext_small(pretrained=True,\n",
    "                                 progress=True,\n",
    "                                 num_classes=num_classes)\n",
    "\n",
    "modelPool = [ALEX, VGG, GOOGLE, MOBILE, CONVNEXT]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = SoftTargetCrossEntropy()\n",
    "# model.fc = nn.Sequential(nn.Linear(2048,1024), nn.ReLU(), nn.Dropout(0.2),\n",
    "#                          nn.Linear(512, 7), nn.LogSoftmax(dim=1))\n",
    "# model.fc = nn.Sequential(nn.LogSoftmax(dim=1))\n",
    "model = modelPool[0]\n",
    "model.to(device)\n",
    "# 选择简单暴力的Adam优化器，学习率调低\n",
    "# optimizer = optim.Adam(model_ft.parameters(), lr=modellr)\n",
    "# optimizer = optim.SGD(model_ft.parameters(),lr=modellr)\n",
    "optimizer = optim.RAdam(model.parameters(), lr=lr)\n",
    "cosine_schedule = optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer,\n",
    "                                                       T_max=20,\n",
    "                                                       eta_min=1e-9)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=0.01, steps_per_epoch=len(dataset_train), epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_COUNT = 0\n",
    "ACC_LIST = []\n",
    "LOSS_LIST = []\n",
    "ACC = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    lr_now = lr\n",
    "    total_num = len(train_loader.dataset)\n",
    "    print(total_num, len(train_loader))\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = (\n",
    "            data.to(device, non_blocking=True),\n",
    "            target.to(device, non_blocking=True),\n",
    "        )\n",
    "        data, labels_a, labels_b, lam = mixup_data(data, target, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        # output = model(data)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss = mixup_criterion(criterion, model(data), labels_a, labels_b,\n",
    "                                   lam)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scheduler.step()\n",
    "        lr_now = scheduler.get_last_lr()\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        print_loss = loss.data.item()\n",
    "        sum_loss += print_loss\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tlr={}\".\n",
    "                  format(\n",
    "                      epoch,\n",
    "                      (batch_idx + 1) * len(data),\n",
    "                      len(train_loader.dataset),\n",
    "                      100.0 * (batch_idx + 1) / len(train_loader),\n",
    "                      loss.item(),\n",
    "                      lr_now,\n",
    "                  ))\n",
    "    ave_loss = sum_loss / len(train_loader)\n",
    "    LOSS_LIST.append(ave_loss)\n",
    "    print(\"Epoch:{},loss:{},lr:{}\".format(epoch, ave_loss, lr_now))\n",
    "\n",
    "\n",
    "# 验证过程\n",
    "def val(model, device, test_loader):\n",
    "    global ACC\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_num = len(test_loader.dataset)\n",
    "    print(total_num, len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data).to(device), Variable(target).to(\n",
    "                device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += torch.sum(pred == target)\n",
    "            print_loss = loss.data.item()\n",
    "            test_loss += print_loss\n",
    "        correct = correct.data.item()\n",
    "        acc = correct / total_num\n",
    "        avgloss = test_loss / len(test_loader)\n",
    "        print(\"\\nVal set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".\n",
    "              format(avgloss, correct, len(test_loader.dataset), 100 * acc))\n",
    "        ACC_LIST.append(acc)\n",
    "        if acc > ACC:\n",
    "            torch.save(\n",
    "                model,\n",
    "                \"model_\" + str(epoch) + \"_\" + str(round(acc, 3)) + \".pth\")\n",
    "            ACC = acc\n",
    "\n",
    "\n",
    "# 训练\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    cosine_schedule.step()\n",
    "    val(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(palette=\"twilight\")\n",
    "sns.relplot(kind=\"line\", data=ACC_LIST)\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch Time\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "print(ACC_LIST)\n",
    "# plt.ylim(top=1,bottom=0)\n",
    "sns.relplot(kind=\"line\", data=LOSS_LIST)\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch Time\")\n",
    "plt.ylabel(\"Loss\")\n",
    "print(LOSS_LIST)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1882425c3b4fabc3d9812b2bb88e573da3722c6cd108cda16b062a3868ec4930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
